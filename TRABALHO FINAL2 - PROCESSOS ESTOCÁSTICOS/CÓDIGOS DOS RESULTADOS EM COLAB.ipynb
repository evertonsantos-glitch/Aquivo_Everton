{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcgQRqT6MNvr4RfO22DiWC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":593},"id":"WA91ujGqWaf1","executionInfo":{"status":"ok","timestamp":1756161129731,"user_tz":180,"elapsed":18532,"user":{"displayName":"EVERTON COSTA SANTOS","userId":"03207008569162205286"}},"outputId":"df28de5e-3863-41a1-dcf3-d0eb8c00ca29"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-55e07e13-bf40-414e-a823-089ccb743694\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-55e07e13-bf40-414e-a823-089ccb743694\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving TRABALHO ESTOCÁSTICOS4 - Final - Base.csv to TRABALHO ESTOCÁSTICOS4 - Final - Base.csv\n","Estatísticas — Consumo às 04h em Março\n","---------------------------------------------\n","Tamanho da amostra:             403\n","Média:                          13758.0223\n","Mediana:                        13737.0000\n","Modas (2):                 12884.0000, 13510.0000\n","Mínimo:                         9917.0000\n","Máximo:                         19240.0000\n","Amplitude:                      9323.0000\n","Desvio-padrão (amostral):       1700.2358\n","Variância da amostra:           2890801.9174\n","Coeficiente de Variação:        0.123581\n","Coeficiente de Assimetria:      0.196110\n","\n","Resumo por ano (março às 04:00):\n","       N         Media    Min    Max\n","Ano                                 \n","2005  31  14239.774194  11552  16830\n","2006  31  14196.709677  11420  16213\n","2007  31  13983.612903  11272  16873\n","2008  31  14980.322581  13567  17180\n","2009  31  13422.258065  10891  18956\n","2010  31  13610.193548  11477  16453\n","2011  31  14105.774194  11754  15760\n","2012  31  12314.612903  10329  16481\n","2013  31  14534.580645  11380  16739\n","2014  31  14464.516129  11944  19240\n","2015  31  13763.032258  11713  18793\n","2016  31  12081.806452  10236  15741\n","2017  31  13157.096774   9917  17310\n"]}],"source":["# CÁLCULO DA ESTATÍSTICA DESCRITIVA (ABORDAGEM IID)\n","\n","import io\n","import math\n","import numpy as np\n","import pandas as pd\n","\n","# Upload do CSV\n","try:\n","    from google.colab import files  # type: ignore\n","    uploaded = files.upload()\n","    filename = next(iter(uploaded))\n","    df = pd.read_csv(io.BytesIO(uploaded[filename]))\n","except Exception as e:\n","    raise RuntimeError(\"Falha ao carregar o arquivo. Tente novamente o upload do CSV.\") from e\n","\n","# Parse de datas\n","if 'Data' not in df.columns or 'Consumo' not in df.columns:\n","    raise ValueError(\"O CSV precisa conter as colunas 'Data' e 'Consumo'.\")\n","\n","df['Data'] = pd.to_datetime(df['Data'])\n","\n","# Filtra março e horário 04:00\n","mask_marco_4h = (df['Data'].dt.month == 3) & (df['Data'].dt.hour == 4)\n","amostra = df.loc[mask_marco_4h, 'Consumo'].astype(float).reset_index(drop=True)\n","\n","if amostra.empty:\n","    raise ValueError(\"Não foram encontrados registros para março às 04:00 no arquivo fornecido.\")\n","\n","# --- Estatísticas ---\n","n = amostra.shape[0]\n","media = amostra.mean()\n","mediana = amostra.median()\n","\n","# Modas (podem existir múltiplas)\n","modas = amostra.mode().tolist()\n","moda = modas[0] if len(modas) > 0 else np.nan  # moda principal (primeira)\n","\n","minimo = amostra.min()\n","maximo = amostra.max()\n","amplitude = maximo - minimo\n","\n","# Desvio-padrão e variância amostrais (ddof=1)\n","desvio_padrao_amostral = amostra.std(ddof=1)\n","variancia_amostral = amostra.var(ddof=1)\n","\n","# Coeficiente de Variação (CV = s / média). Se média=0, define como NaN\n","coef_var = desvio_padrao_amostral / media if media != 0 else np.nan\n","\n","# Coeficiente de Assimetria (skewness) com correção de viés.\n","# Preferimos scipy (se disponível). Caso contrário, usamos pandas (que já aplica correção).\n","def skewness_series(s: pd.Series) -> float:\n","    try:\n","        from scipy.stats import skew  # type: ignore\n","        return float(skew(s.values, bias=False, nan_policy='omit'))\n","    except Exception:\n","        return float(s.skew())  # pandas: já é a versão amostral\n","\n","coef_assimetria = skewness_series(amostra)\n","\n","# --- Impressão formatada ---\n","print(\"Estatísticas — Consumo às 04h em Março\")\n","print(\"-\" * 45)\n","print(f\"Tamanho da amostra:             {n}\")\n","print(f\"Média:                          {media:.4f}\")\n","print(f\"Mediana:                        {mediana:.4f}\")\n","if len(modas) == 1:\n","    print(f\"Moda:                           {moda:.4f}\")\n","else:\n","    # Exibe todas as modas, se houver mais de uma\n","    modas_fmt = \", \".join(f\"{m:.4f}\" for m in modas)\n","    print(f\"Modas ({len(modas)}):                 {modas_fmt}\")\n","print(f\"Mínimo:                         {minimo:.4f}\")\n","print(f\"Máximo:                         {maximo:.4f}\")\n","print(f\"Amplitude:                      {amplitude:.4f}\")\n","print(f\"Desvio-padrão (amostral):       {desvio_padrao_amostral:.4f}\")\n","print(f\"Variância da amostra:           {variancia_amostral:.4f}\")\n","print(f\"Coeficiente de Variação:        {coef_var:.6f}\")\n","print(f\"Coeficiente de Assimetria:      {coef_assimetria:.6f}\")\n","\n","# (Opcional) Mostrar um resumo rápido por ano: média de março às 4h por ano\n","resumo_ano = (\n","    df.loc[mask_marco_4h, ['Data', 'Consumo']]\n","      .assign(Ano=lambda x: x['Data'].dt.year)\n","      .groupby('Ano')['Consumo'].agg(['count', 'mean', 'min', 'max'])\n","      .rename(columns={'count': 'N', 'mean': 'Media', 'min': 'Min', 'max': 'Max'})\n",")\n","print(\"\\nResumo por ano (março às 04:00):\")\n","print(resumo_ano)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"3V1krjfzjRUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CÁLCULO PARA O BOX PLOT MODIFICADO (ABORDAGEM IID)\n","\n","import io\n","import pandas as pd\n","\n","# Upload do CSV\n","try:\n","    from google.colab import files  # type: ignore\n","    uploaded = files.upload()\n","    filename = next(iter(uploaded))\n","    df = pd.read_csv(io.BytesIO(uploaded[filename]))\n","except Exception as e:\n","    raise RuntimeError(\"Falha ao carregar o arquivo. Refaça o upload do CSV.\") from e\n","\n","# Checagens básicas\n","if 'Data' not in df.columns or 'Consumo' not in df.columns:\n","    raise ValueError(\"O CSV precisa conter as colunas 'Data' e 'Consumo'.\")\n","\n","# Preparação\n","df['Data'] = pd.to_datetime(df['Data'])\n","\n","# Filtra março e horário 04:00\n","amostra_df = df[(df['Data'].dt.month == 3) & (df['Data'].dt.hour == 4)][['Data','Consumo']].copy()\n","amostra = amostra_df['Consumo'].astype(float)\n","\n","if amostra.empty:\n","    raise ValueError(\"Não há registros para março às 04:00 no arquivo fornecido.\")\n","\n","# Quartis e limites do box plot modificado\n","Q1 = amostra.quantile(0.25)\n","Q3 = amostra.quantile(0.75)\n","AIQ = Q3 - Q1\n","Li = Q1 - 1.5 * AIQ\n","Ls = Q3 + 1.5 * AIQ\n","\n","# Whiskers (mínimo/máximo dentro dos limites)\n","whisker_min = amostra[amostra >= Li].min()\n","whisker_max = amostra[amostra <= Ls].max()\n","\n","# Outliers moderados\n","outliers_baixos = amostra_df[amostra_df['Consumo'] < Li].copy()\n","outliers_altos  = amostra_df[amostra_df['Consumo'] > Ls].copy()\n","\n","outliers_baixos['Tipo'] = 'Abaixo de Li'\n","outliers_altos['Tipo']  = 'Acima de Ls'\n","\n","outliers = pd.concat([outliers_baixos, outliers_altos], ignore_index=True).sort_values('Data').reset_index(drop=True)\n","\n","# Impressão dos resultados\n","print(\"Parâmetros do Box Plot Modificado — Consumo às 04h em Março\")\n","print(\"-\" * 70)\n","print(f\"Tamanho da amostra (n):  {len(amostra)}\")\n","print(f\"Q1 (1º quartil):         {Q1:.4f}\")\n","print(f\"Q3 (3º quartil):         {Q3:.4f}\")\n","print(f\"AIQ (Q3 - Q1):           {AIQ:.4f}\")\n","print(f\"Limite inferior (Li):    {Li:.4f}\")\n","print(f\"Limite superior (Ls):    {Ls:.4f}\")\n","print(f\"Whisker mínimo:          {whisker_min:.4f}\")\n","print(f\"Whisker máximo:          {whisker_max:.4f}\")\n","\n","print(\"\\nResumo de outliers moderados:\")\n","print(f\" - Abaixo de Li: {len(outliers_baixos)}\")\n","print(f\" - Acima de Ls:  {len(outliers_altos)}\")\n","print(f\" - Total:        {len(outliers)}\")\n","\n","# Mostra alguns outliers, se existirem\n","if not outliers.empty:\n","    display_cols = ['Data', 'Consumo', 'Tipo']\n","    try:\n","        from IPython.display import display\n","        display(outliers[display_cols])\n","    except Exception:\n","        print(\"\\nOutliers (primeiras linhas):\")\n","        print(outliers[display_cols].head())\n","\n","# (Opcional) salvar CSV com os outliers\n","salvar_csv = True\n","if salvar_csv and not outliers.empty:\n","    nome_arquivo = \"outliers_marco_4h.csv\"\n","    outliers.to_csv(nome_arquivo, index=False)\n","    try:\n","        files.download(nome_arquivo)\n","    except Exception:\n","        print(f\"\\nArquivo salvo em disco: {nome_arquivo}\")\n"],"metadata":{"id":"s21qtuftZR7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# HISTOGRAMA + TESTE KS +  TESTE DE LJUNG–BOX (ABORDAGEM IID)\n","\n","import io\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Imports estatísticos\n","from scipy import stats\n","from statsmodels.stats.diagnostic import acorr_ljungbox\n","\n","# === Upload do CSV (Colab) ===\n","try:\n","    from google.colab import files  # type: ignore\n","    uploaded = files.upload()\n","    filename = next(iter(uploaded))\n","    df = pd.read_csv(io.BytesIO(uploaded[filename]))\n","except Exception as e:\n","    raise RuntimeError(\"Falha ao carregar o arquivo. Faça o upload do CSV e tente novamente.\") from e\n","\n","# === Checagens básicas ===\n","if 'Data' not in df.columns or 'Consumo' not in df.columns:\n","    raise ValueError(\"O CSV precisa conter as colunas 'Data' e 'Consumo'.\")\n","\n","# === Preparação da amostra: março às 04:00 ===\n","df['Data'] = pd.to_datetime(df['Data'])\n","amostra_df = df[(df['Data'].dt.month == 3) & (df['Data'].dt.hour == 4)][['Data','Consumo']].copy()\n","\n","if amostra_df.empty:\n","    raise ValueError(\"Não há registros para março às 04:00 no arquivo fornecido.\")\n","\n","amostra = amostra_df['Consumo'].astype(float).dropna().reset_index(drop=True)\n","\n","# === Parâmetros da amostra ===\n","n = len(amostra)\n","media = amostra.mean()\n","# Desvio-padrão amostral (ddof=1)\n","desvio = amostra.std(ddof=1)\n","\n","# === Número de classes pelo método de Rice ===\n","# k = ceil(2 * n^(1/3))\n","k_rice = int(np.ceil(2 * n ** (1/3)))\n","\n","# === Plot: histograma (densidade) + curva normal ajustada ===\n","plt.figure(figsize=(8, 5))\n","# Histograma como densidade para compatibilizar com a PDF normal\n","contagens, bin_edges, _ = plt.hist(amostra, bins=k_rice, density=True, alpha=0.5)\n","# Intervalo para a curva\n","x = np.linspace(amostra.min(), amostra.max(), 400)\n","pdf_normal = stats.norm.pdf(x, loc=media, scale=desvio)\n","plt.plot(x, pdf_normal, linewidth=2)\n","\n","plt.title(\"Consumo às 04:00 em Março — Histograma (Rice) + Normal Ajustada\")\n","plt.xlabel(\"Consumo\")\n","plt.ylabel(\"Densidade\")\n","plt.grid(True, linestyle=\"--\", linewidth=0.5)\n","plt.show()\n","\n","# === Teste KS para N(media, desvio^2) ===\n","# Observação: parâmetros estimados da amostra => p-valor do KS é aproximado (Lilliefors seria o ideal).\n","ks_stat, ks_p = stats.kstest(amostra, 'norm', args=(media, desvio))\n","\n","print(\"=== Teste Kolmogorov–Smirnov para Normal Ajustada ===\")\n","print(f\"n = {n}\")\n","print(f\"Média = {media:.6f} | Desvio-padrão(amostral) = {desvio:.6f}\")\n","print(f\"Bins (Rice) = {k_rice}\")\n","print(f\"KS estatística = {ks_stat:.6f} | p-valor = {ks_p:.6f}\")\n","\n","alpha = 0.05\n","if ks_p < alpha:\n","    print(f\"Decisão (α={alpha:.2f}): Rejeitar H0 (a amostra difere da Normal ajustada).\")\n","else:\n","    print(f\"Decisão (α={alpha:.2f}): Não rejeitar H0 (compatível com Normal ajustada).\")\n","\n","# === Teste Ljung–Box (lag = 10) ===\n","# H0: ausência de autocorrelação até a defasagem indicada.\n","lb_df = acorr_ljungbox(amostra, lags=[10], return_df=True)\n","lb_stat = float(lb_df['lb_stat'].iloc[0])\n","lb_p = float(lb_df['lb_pvalue'].iloc[0])\n","\n","print(\"\\n=== Teste Ljung–Box ===\")\n","print(f\"Lag = 10 | Estatística = {lb_stat:.6f} | p-valor = {lb_p:.6e}\")\n","if lb_p < alpha:\n","    print(f\"Decisão (α={alpha:.2f}): Rejeitar H0 — evidência de autocorrelação (não-aleatoriedade).\")\n","else:\n","    print(f\"Decisão (α={alpha:.2f}): Não rejeitar H0 — sem evidência de autocorrelação.\")\n"],"metadata":{"id":"2yPqolASbhqB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TESTE DE ESTACIONARIEDADE ESTACIONARIEDADE (ABORDAGEM DE SÉRIES TEMPORAIS)\n","\n","import pandas as pd\n","import numpy as np\n","from statsmodels.tsa.stattools import adfuller\n","\n","# === 1) Ler o CSV ===\n","# Ajuste o caminho se necessário\n","csv_path = \"TRABALHO ESTOCÁSTICOS4 - Final - Base.csv\"\n","df = pd.read_csv(csv_path)\n","\n","# === 2) Detectar e converter a coluna de data/hora (sem infer_datetime_format) ===\n","# tenta nomes comuns; se não achar, tenta a 1ª coluna de texto parseável\n","candidatas_dt = [c for c in df.columns\n","                 if c.lower() in [\"datetime\",\"data\",\"date\",\"timestamp\",\"time\",\"hora\",\"dt\"]]\n","\n","if candidatas_dt:\n","    dt_col = candidatas_dt[0]\n","else:\n","    dt_col = None\n","    for c in df.select_dtypes(include=\"object\").columns:\n","        try:\n","            pd.to_datetime(df[c], errors=\"raise\")\n","            dt_col = c\n","            break\n","        except Exception:\n","            pass\n","    if dt_col is None:\n","        raise ValueError(\"Não foi possível localizar uma coluna de data/hora; informe-a em dt_col.\")\n","\n","df[\"dt\"] = pd.to_datetime(df[dt_col], errors=\"coerce\")  # <-- sem infer_datetime_format\n","df = df.dropna(subset=[\"dt\"]).sort_values(\"dt\").set_index(\"dt\")\n","\n","# === 3) Detectar a coluna numérica de consumo ===\n","num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n","if not num_cols:\n","    # tenta converter possíveis colunas com vírgula decimal\n","    for c in df.columns:\n","        if c != \"dt\":\n","            df[c] = pd.to_numeric(df[c].astype(str).str.replace(\",\", \".\"), errors=\"coerce\")\n","    num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n","\n","if not num_cols:\n","    raise ValueError(\"Não foi encontrada coluna numérica de consumo.\")\n","valor_col = num_cols[0] if len(num_cols) == 1 else df[num_cols].count().idxmax()\n","\n","# === 4) Recorte: todo novembro de 2016 ===\n","ts_nov2016 = df.loc[\"2016-11-01\":\"2016-11-30 23:59:59\", valor_col].dropna()\n","\n","# Sanidade: precisa de > 0 observações\n","if ts_nov2016.empty:\n","    raise ValueError(\"O recorte de novembro/2016 ficou vazio. Confira o fuso/colunas/arquivo.\")\n","\n","# === 5) Teste ADF ===\n","adf_stat, p_value, usedlag, nobs, crit_vals, icbest = adfuller(ts_nov2016.values, autolag=\"AIC\")\n","\n","print(\"Período analisado: 2016-11-01 a 2016-11-30\")\n","print(f\"Tamanho da amostra: {int(nobs)}\")\n","print(f\"Estatística ADF: {adf_stat:.3f}\")\n","print(f\"Valor-p: {p_value:.3g}\")\n","print(\"Valores críticos:\")\n","for k, v in crit_vals.items():\n","    print(f\"  {k}%: {v:.3f}\")\n","\n","alpha = 0.05\n","conclusao = (\"Série estacionária (rejeita H0 de raiz unitária)\"\n","             if p_value < alpha else\n","             \"Série NÃO estacionária (não rejeita H0 de raiz unitária)\")\n","print(\"Conclusão (α=5%):\", conclusao)\n"],"metadata":{"id":"tapDztLBgFRG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SÉRIE DIFERENCIADA + GRÁFICO ACF + GRÁFICO PACF (ABORDAGEM DE SÉRIES TEMPORAIS)\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","\n","# ---------- Config ----------\n","csv_path = \"TRABALHO ESTOCÁSTICOS4 - Final - Base.csv\"  # ajuste se estiver em outro caminho\n","nome_col_data_preferidos = [\"Data\",\"datetime\",\"date\",\"timestamp\",\"hora\",\"time\",\"dt\"]\n","nome_col_valor_preferidos = [\"Consumo\",\"valor\",\"load\",\"mw\",\"aep_mw\"]\n","\n","# ---------- Leitura ----------\n","df = pd.read_csv(csv_path)\n","\n","# Detecta coluna de data\n","dt_col = None\n","for c in df.columns:\n","    if c.lower() in [n.lower() for n in nome_col_data_preferidos]:\n","        dt_col = c\n","        break\n","if dt_col is None:\n","    for c in df.select_dtypes(include=\"object\").columns:\n","        try:\n","            pd.to_datetime(df[c], errors=\"raise\")\n","            dt_col = c\n","            break\n","        except Exception:\n","            pass\n","if dt_col is None:\n","    raise ValueError(\"Não encontrei coluna de data/hora. Informe-a manualmente (ex.: dt_col = 'Data').\")\n","\n","# Converte datas (sem infer_datetime_format) e ordena\n","df[\"dt\"] = pd.to_datetime(df[dt_col], errors=\"coerce\")\n","df = df.dropna(subset=[\"dt\"]).sort_values(\"dt\").set_index(\"dt\")\n","\n","# Detecta coluna numérica de consumo\n","val_col = None\n","for c in df.columns:\n","    if c == \"dt\":\n","        continue\n","    if c.lower() in [n.lower() for n in nome_col_valor_preferidos]:\n","        val_col = c\n","        break\n","if val_col is None:\n","    # tenta numéricas diretas\n","    num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n","    if not num_cols:\n","        # tenta converter trocando vírgula por ponto\n","        for c in df.columns:\n","            if c != \"dt\":\n","                df[c] = pd.to_numeric(df[c].astype(str).str.replace(\",\", \".\"), errors=\"coerce\")\n","        num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n","    if not num_cols:\n","        raise ValueError(\"Não encontrei coluna numérica de consumo. Defina manualmente (ex.: val_col = 'Consumo').\")\n","    # escolhe a com mais dados\n","    val_col = df[num_cols].count().idxmax()\n","\n","# ---------- Recorte novembro/2016 ----------\n","ts = df[val_col].astype(float).sort_index()\n","ts_nov = ts.loc[\"2016-11-01\":\"2016-11-30 23:59:59\"].dropna()\n","if ts_nov.empty:\n","    raise ValueError(\"Sem dados para novembro/2016 no arquivo.\")\n","\n","# ---------- Diferenciação d = 1 ----------\n","ts_diff = ts_nov.diff().dropna()\n","\n","# ---------- Plot: série diferenciada ----------\n","plt.figure(figsize=(10,4))\n","plt.plot(ts_diff.index, ts_diff.values)\n","plt.title(\"Série Diferenciada (d = 1) — Novembro/2016\")\n","plt.xlabel(\"Data\")\n","plt.ylabel(\"Δ Consumo\")\n","plt.grid(True, linestyle=\"--\", linewidth=0.5)\n","plt.tight_layout()\n","plt.show()\n","\n","# ---------- Plot: ACF ----------\n","plt.figure(figsize=(8,4))\n","plot_acf(ts_diff, lags=40, alpha=0.05)  # 40 defasagens é usual para base horária mensal\n","plt.title(\"ACF da Série Diferenciada (d = 1)\")\n","plt.tight_layout()\n","plt.show()\n","\n","# ---------- Plot: PACF ----------\n","plt.figure(figsize=(8,4))\n","plot_pacf(ts_diff, lags=40, alpha=0.05, method=\"ywm\")  # Yule-Walker modificado é estável\n","plt.title(\"PACF da Série Diferenciada (d = 1)\")\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"N observações em nov/2016: {len(ts_nov)} | Após diff: {len(ts_diff)}\")\n"],"metadata":{"id":"zoHf7T9CX-K4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MODELO MATEMÁTICO DO ARIMA(1,1,1)- (ABORDAGEM DE SÉRIES TEMPORAIS)\n","\n","!pip -q install statsmodels pandas\n","\n","import pandas as pd\n","import statsmodels.api as sm\n","\n","# --- 1) Upload do CSV ---\n","from google.colab import files\n","uploaded = files.upload()   # selecione: TRABALHO ESTOCÁSTICOS4 - Final - Base.csv\n","csv_path = list(uploaded.keys())[0]\n","\n","# --- 2) Ler dados ---\n","df = pd.read_csv(csv_path)\n","df[\"Data\"] = pd.to_datetime(df[\"Data\"])\n","\n","# --- 3) Filtrar novembro/2016 ---\n","serie = df.loc[(df[\"Data\"].dt.year==2016) & (df[\"Data\"].dt.month==11), \"Consumo\"]\n","\n","# --- 4) Ajustar ARIMA(1,1,1) ---\n","modelo = sm.tsa.ARIMA(serie, order=(1,1,1))\n","resultado = modelo.fit()\n","\n","# --- 5) Exibir coeficientes ---\n","print(\"Resumo:\")\n","print(resultado.summary())\n","\n","print(\"\\nCoeficientes principais:\")\n","print(\"AR(1) =\", resultado.params[\"ar.L1\"])\n","print(\"MA(1) =\", resultado.params[\"ma.L1\"])\n","print(\"σ²    =\", resultado.params[\"sigma2\"])\n"],"metadata":{"id":"uyODcgPn96vG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CÁLCULO DO MAPE- (ABORDAGEM DE SÉRIES TEMPORAIS)\n","\n","!pip -q install statsmodels pandas numpy\n","\n","import numpy as np\n","import pandas as pd\n","from statsmodels.tsa.arima.model import ARIMA\n","\n","# 1) Upload do arquivo CSV\n","from google.colab import files\n","uploaded = files.upload()  # selecione: TRABALHO ESTOCÁSTICOS4 - Final - Base.csv\n","csv_path = list(uploaded.keys())[0]\n","print(\"Arquivo carregado:\", csv_path)\n","\n","# 2) Ler base e filtrar nov/2016\n","df = pd.read_csv(csv_path)\n","df[\"Data\"] = pd.to_datetime(df[\"Data\"])\n","mask = (df[\"Data\"].dt.year == 2016) & (df[\"Data\"].dt.month == 11)\n","y = df.loc[mask, \"Consumo\"].astype(float).reset_index(drop=True)\n","\n","print(\"Tamanho da amostra (nov/2016):\", len(y))  # esperado: 721\n","\n","# 3) Ajustar ARIMA(1,1,1)\n","model = ARIMA(y, order=(1, 1, 1))\n","res = model.fit()\n","\n","# 4) Previsão one-step ahead in-sample (dynamic=False) e MAPE\n","fitted = res.fittedvalues              # já no espaço de Y_t\n","y_aligned = y.copy()\n","fitted_aligned = fitted.reindex_like(y_aligned)\n","\n","mask_valid = ~fitted_aligned.isna() & (y_aligned != 0)\n","mape = (np.abs((y_aligned[mask_valid] - fitted_aligned[mask_valid]) / y_aligned[mask_valid])).mean() * 100\n","\n","# 5) Coeficientes e equação\n","phi1 = res.params.get(\"ar.L1\", np.nan)\n","theta1 = res.params.get(\"ma.L1\", np.nan)\n","sigma2 = res.params.get(\"sigma2\", np.nan)\n","\n","print(\"\\n=== Coeficientes ARIMA(1,1,1) ===\")\n","print(f\"AR(1)  = {phi1:.6f}\")\n","print(f\"MA(1)  = {theta1:.6f}\")\n","print(f\"sigma^2= {sigma2:.6f}\")\n","\n","print(\"\\n=== Equação (d=1) ===\")\n","print(\"ΔY_t = φ1 * ΔY_{t-1} + ε_t + θ1 * ε_{t-1}\")\n","print(f\"ΔY_t = {phi1:.4f} * ΔY_(t-1) + ε_t + {theta1:.4f} * ε_(t-1)\")\n","\n","print(\"\\n=== MAPE in-sample (one-step ahead) ===\")\n","print(f\"MAPE = {mape:.3f}%\")\n","\n","# (Opcional) mostrar 10 primeiras previsões vs observados\n","preview = pd.DataFrame({\n","    \"Y_observado\": y_aligned,\n","    \"Y_previsto_1passo\": fitted_aligned\n","}).dropna().head(10)\n","print(\"\\nObservado vs. Previsto (primeiros 10 pontos):\")\n","print(preview.to_string(index=False))\n"],"metadata":{"id":"_OJAbFIU_XLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TESTE  LJUNG-BOX NOS RESÍDUOS- (ABORDAGEM DE SÉRIES TEMPORAIS)\n","!pip -q install statsmodels pandas numpy\n","\n","import numpy as np\n","import pandas as pd\n","from statsmodels.tsa.arima.model import ARIMA\n","from statsmodels.stats.diagnostic import acorr_ljungbox\n","\n","# 1) Upload do CSV\n","from google.colab import files\n","uploaded = files.upload()  # escolha: TRABALHO ESTOCÁSTICOS4 - Final - Base.csv\n","csv_path = list(uploaded.keys())[0]\n","\n","# 2) Leitura e filtro nov/2016\n","df = pd.read_csv(csv_path)\n","df[\"Data\"] = pd.to_datetime(df[\"Data\"])\n","mask = (df[\"Data\"].dt.year == 2016) & (df[\"Data\"].dt.month == 11)\n","y = df.loc[mask, \"Consumo\"].astype(float).reset_index(drop=True)\n","\n","# 3) Ajuste ARIMA(1,1,1)\n","res = ARIMA(y, order=(1,1,1)).fit()\n","\n","# 4) Resíduos in-sample (one-step, dynamic=False) e Ljung-Box\n","resid = res.resid.dropna()\n","\n","# lags que você quer avaliar\n","lags_to_test = [10, 20, 30]\n","lb = acorr_ljungbox(resid, lags=lags_to_test, return_df=True)\n","\n","print(\"=== Coeficientes do ARIMA(1,1,1) ===\")\n","print(f\"AR(1) = {res.params.get('ar.L1'): .6f}\")\n","print(f\"MA(1) = {res.params.get('ma.L1'): .6f}\\n\")\n","\n","print(\"=== Teste de Ljung-Box nos resíduos ===\")\n","# renomear colunas para clareza\n","lb = lb.rename(columns={\"lb_stat\": \"Estatística\", \"lb_pvalue\": \"p_valor\"})\n","print(lb.to_string(index=True))\n","\n","# 5) Interpretação simples (alpha=0.05)\n","alpha = 0.05\n","for lag, p in zip(lb.index, lb[\"p_valor\"]):\n","    concl = \"NÃO rejeita autocorrelação (OK)\" if p > alpha else \"Rejeita: há autocorrelação\"\n","    print(f\"Lag {lag:>2}: p={p:.3g} → {concl}\")\n"],"metadata":{"id":"DqT5ofdBBYO2"},"execution_count":null,"outputs":[]}]}